{"ast":null,"code":"\"use strict\";\n\nvar _interopRequireDefault = require(\"@babel/runtime/helpers/interopRequireDefault\");\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.processCsvData = processCsvData;\nexports.parseRowsByFields = parseRowsByFields;\nexports.getSampleForTypeAnalyze = getSampleForTypeAnalyze;\nexports.parseCsvRowsByFieldType = parseCsvRowsByFieldType;\nexports.getFieldsFromData = getFieldsFromData;\nexports.renameDuplicateFields = renameDuplicateFields;\nexports.analyzerTypeToFieldType = analyzerTypeToFieldType;\nexports.processRowObject = processRowObject;\nexports.processGeojson = processGeojson;\nexports.formatCsv = formatCsv;\nexports.validateInputData = validateInputData;\nexports.processKeplerglJSON = processKeplerglJSON;\nexports.processKeplerglDataset = processKeplerglDataset;\nexports.Processors = exports.DATASET_HANDLERS = exports.PARSE_FIELD_VALUE_FROM_STRING = exports.CSV_NULLS = exports.ACCEPTED_ANALYZER_TYPES = void 0;\nvar _typeof2 = _interopRequireDefault(require(\"@babel/runtime/helpers/typeof\"));\nvar _defineProperty2 = _interopRequireDefault(require(\"@babel/runtime/helpers/defineProperty\"));\nvar _d3Dsv = require(\"d3-dsv\");\nvar _d3Array = require(\"d3-array\");\nvar _window = require(\"global/window\");\nvar _assert = _interopRequireDefault(require(\"assert\"));\nvar _typeAnalyzer = require(\"type-analyzer\");\nvar _geojsonNormalize = _interopRequireDefault(require(\"@mapbox/geojson-normalize\"));\nvar _defaultSettings = require(\"../constants/default-settings\");\nvar _dataUtils = require(\"../utils/data-utils\");\nvar _schemas = _interopRequireDefault(require(\"../schemas\"));\nvar _userGuides = require(\"../constants/user-guides\");\nvar _utils = require(\"../utils/utils\");\nvar _PARSE_FIELD_VALUE_FR, _DATASET_HANDLERS;\nfunction _createForOfIteratorHelper(o, allowArrayLike) {\n  var it;\n  if (typeof Symbol === \"undefined\" || o[Symbol.iterator] == null) {\n    if (Array.isArray(o) || (it = _unsupportedIterableToArray(o)) || allowArrayLike && o && typeof o.length === \"number\") {\n      if (it) o = it;\n      var i = 0;\n      var F = function F() {};\n      return {\n        s: F,\n        n: function n() {\n          if (i >= o.length) return {\n            done: true\n          };\n          return {\n            done: false,\n            value: o[i++]\n          };\n        },\n        e: function e(_e) {\n          throw _e;\n        },\n        f: F\n      };\n    }\n    throw new TypeError(\"Invalid attempt to iterate non-iterable instance.\\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.\");\n  }\n  var normalCompletion = true,\n    didErr = false,\n    err;\n  return {\n    s: function s() {\n      it = o[Symbol.iterator]();\n    },\n    n: function n() {\n      var step = it.next();\n      normalCompletion = step.done;\n      return step;\n    },\n    e: function e(_e2) {\n      didErr = true;\n      err = _e2;\n    },\n    f: function f() {\n      try {\n        if (!normalCompletion && it[\"return\"] != null) it[\"return\"]();\n      } finally {\n        if (didErr) throw err;\n      }\n    }\n  };\n}\nfunction _unsupportedIterableToArray(o, minLen) {\n  if (!o) return;\n  if (typeof o === \"string\") return _arrayLikeToArray(o, minLen);\n  var n = Object.prototype.toString.call(o).slice(8, -1);\n  if (n === \"Object\" && o.constructor) n = o.constructor.name;\n  if (n === \"Map\" || n === \"Set\") return Array.from(o);\n  if (n === \"Arguments\" || /^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(n)) return _arrayLikeToArray(o, minLen);\n}\nfunction _arrayLikeToArray(arr, len) {\n  if (len == null || len > arr.length) len = arr.length;\n  for (var i = 0, arr2 = new Array(len); i < len; i++) {\n    arr2[i] = arr[i];\n  }\n  return arr2;\n}\nfunction ownKeys(object, enumerableOnly) {\n  var keys = Object.keys(object);\n  if (Object.getOwnPropertySymbols) {\n    var symbols = Object.getOwnPropertySymbols(object);\n    if (enumerableOnly) symbols = symbols.filter(function (sym) {\n      return Object.getOwnPropertyDescriptor(object, sym).enumerable;\n    });\n    keys.push.apply(keys, symbols);\n  }\n  return keys;\n}\nfunction _objectSpread(target) {\n  for (var i = 1; i < arguments.length; i++) {\n    var source = arguments[i] != null ? arguments[i] : {};\n    if (i % 2) {\n      ownKeys(Object(source), true).forEach(function (key) {\n        (0, _defineProperty2[\"default\"])(target, key, source[key]);\n      });\n    } else if (Object.getOwnPropertyDescriptors) {\n      Object.defineProperties(target, Object.getOwnPropertyDescriptors(source));\n    } else {\n      ownKeys(Object(source)).forEach(function (key) {\n        Object.defineProperty(target, key, Object.getOwnPropertyDescriptor(source, key));\n      });\n    }\n  }\n  return target;\n}\nvar ACCEPTED_ANALYZER_TYPES = [_typeAnalyzer.DATA_TYPES.DATE, _typeAnalyzer.DATA_TYPES.TIME, _typeAnalyzer.DATA_TYPES.DATETIME, _typeAnalyzer.DATA_TYPES.NUMBER, _typeAnalyzer.DATA_TYPES.INT, _typeAnalyzer.DATA_TYPES.FLOAT, _typeAnalyzer.DATA_TYPES.BOOLEAN, _typeAnalyzer.DATA_TYPES.STRING, _typeAnalyzer.DATA_TYPES.GEOMETRY, _typeAnalyzer.DATA_TYPES.GEOMETRY_FROM_STRING, _typeAnalyzer.DATA_TYPES.PAIR_GEOMETRY_FROM_STRING, _typeAnalyzer.DATA_TYPES.ZIPCODE, _typeAnalyzer.DATA_TYPES.ARRAY, _typeAnalyzer.DATA_TYPES.OBJECT]; // if any of these value occurs in csv, parse it to null;\n// const CSV_NULLS = ['', 'null', 'NULL', 'Null', 'NaN', '/N'];\n// matches empty string\n\nexports.ACCEPTED_ANALYZER_TYPES = ACCEPTED_ANALYZER_TYPES;\nvar CSV_NULLS = /^(null|NULL|Null|NaN|\\/N||)$/;\nexports.CSV_NULLS = CSV_NULLS;\nvar IGNORE_DATA_TYPES = Object.keys(_typeAnalyzer.DATA_TYPES).filter(function (type) {\n  return !ACCEPTED_ANALYZER_TYPES.includes(type);\n});\nvar PARSE_FIELD_VALUE_FROM_STRING = (_PARSE_FIELD_VALUE_FR = {}, (0, _defineProperty2[\"default\"])(_PARSE_FIELD_VALUE_FR, _defaultSettings.ALL_FIELD_TYPES[\"boolean\"], {\n  valid: function valid(d) {\n    return typeof d === 'boolean';\n  },\n  parse: function parse(d) {\n    return d === 'true' || d === 'True' || d === 'TRUE' || d === '1';\n  }\n}), (0, _defineProperty2[\"default\"])(_PARSE_FIELD_VALUE_FR, _defaultSettings.ALL_FIELD_TYPES.integer, {\n  valid: function valid(d) {\n    return parseInt(d, 10) === d;\n  },\n  parse: function parse(d) {\n    return parseInt(d, 10);\n  }\n}), (0, _defineProperty2[\"default\"])(_PARSE_FIELD_VALUE_FR, _defaultSettings.ALL_FIELD_TYPES.timestamp, {\n  valid: function valid(d, field) {\n    return ['x', 'X'].includes(field.format) ? typeof d === 'number' : typeof d === 'string';\n  },\n  parse: function parse(d, field) {\n    return ['x', 'X'].includes(field.format) ? Number(d) : d;\n  }\n}), (0, _defineProperty2[\"default\"])(_PARSE_FIELD_VALUE_FR, _defaultSettings.ALL_FIELD_TYPES.real, {\n  valid: function valid(d) {\n    return parseFloat(d) === d;\n  },\n  // Note this will result in NaN for some string\n  parse: parseFloat\n}), _PARSE_FIELD_VALUE_FR);\n/**\n * Process csv data, output a data object with `{fields: [], rows: []}`.\n * The data object can be wrapped in a `dataset` and pass to [`addDataToMap`](../actions/actions.md#adddatatomap)\n * @param rawData raw csv string\n * @returns  data object `{fields: [], rows: []}` can be passed to addDataToMaps\n * @type {typeof import('./data-processor').processCsvData}\n * @public\n * @example\n * import {processCsvData} from 'kepler.gl/processors';\n *\n * const testData = `gps_data.utc_timestamp,gps_data.lat,gps_data.lng,gps_data.types,epoch,has_result,id,time,begintrip_ts_utc,begintrip_ts_local,date\n * 2016-09-17 00:09:55,29.9900937,31.2590542,driver_analytics,1472688000000,False,1,2016-09-23T00:00:00.000Z,2016-10-01 09:41:39+00:00,2016-10-01 09:41:39+00:00,2016-09-23\n * 2016-09-17 00:10:56,29.9927699,31.2461142,driver_analytics,1472688000000,False,2,2016-09-23T00:00:00.000Z,2016-10-01 09:46:37+00:00,2016-10-01 16:46:37+00:00,2016-09-23\n * 2016-09-17 00:11:56,29.9907261,31.2312742,driver_analytics,1472688000000,False,3,2016-09-23T00:00:00.000Z,,,2016-09-23\n * 2016-09-17 00:12:58,29.9870074,31.2175827,driver_analytics,1472688000000,False,4,2016-09-23T00:00:00.000Z,,,2016-09-23`\n *\n * const dataset = {\n *  info: {id: 'test_data', label: 'My Csv'},\n *  data: processCsvData(testData)\n * };\n *\n * dispatch(addDataToMap({\n *  datasets: [dataset],\n *  options: {centerMap: true, readOnly: true}\n * }));\n */\n\nexports.PARSE_FIELD_VALUE_FROM_STRING = PARSE_FIELD_VALUE_FROM_STRING;\nfunction processCsvData(rawData, header) {\n  var rows;\n  var headerRow;\n  if (typeof rawData === 'string') {\n    var _parsedRows = (0, _d3Dsv.csvParseRows)(rawData);\n    if (!Array.isArray(_parsedRows) || _parsedRows.length < 2) {\n      // looks like an empty file, throw error to be catch\n      throw new Error('process Csv Data Failed: CSV is empty');\n    }\n    headerRow = _parsedRows[0];\n    rows = _parsedRows.slice(1);\n  } else if (Array.isArray(rawData) && rawData.length) {\n    rows = rawData;\n    headerRow = header;\n    if (!Array.isArray(headerRow)) {\n      // if data is passed in as array of rows and missing header\n      // assume first row is header\n      headerRow = rawData[0];\n      rows = rawData.slice(1);\n    }\n  }\n  if (!rows || !headerRow) {\n    throw new Error('invalid input passed to processCsvData');\n  } // here we assume the csv file that people uploaded will have first row\n  // as name of the column\n\n  cleanUpFalsyCsvValue(rows); // No need to run type detection on every data point\n  // here we get a list of none null values to run analyze on\n\n  var sample = getSampleForTypeAnalyze({\n    fields: headerRow,\n    rows: rows\n  });\n  var fields = getFieldsFromData(sample, headerRow);\n  var parsedRows = parseRowsByFields(rows, fields);\n  return {\n    fields: fields,\n    rows: parsedRows\n  };\n}\n/**\n * Parse rows of csv by analyzed field types. So that `'1'` -> `1`, `'True'` -> `true`\n * @param {Array<Array>} rows\n * @param {Array<Object>} fields\n */\n\nfunction parseRowsByFields(rows, fields) {\n  // Edit rows in place\n  var geojsonFieldIdx = fields.findIndex(function (f) {\n    return f.name === '_geojson';\n  });\n  fields.forEach(parseCsvRowsByFieldType.bind(null, rows, geojsonFieldIdx));\n  return rows;\n}\n/**\n * Getting sample data for analyzing field type.\n *\n * @type {typeof import('./data-processor').getSampleForTypeAnalyze}\n */\n\nfunction getSampleForTypeAnalyze(_ref) {\n  var fields = _ref.fields,\n    rows = _ref.rows,\n    _ref$sampleCount = _ref.sampleCount,\n    sampleCount = _ref$sampleCount === void 0 ? 50 : _ref$sampleCount;\n  var total = Math.min(sampleCount, rows.length); // const fieldOrder = fields.map(f => f.name);\n\n  var sample = (0, _d3Array.range)(0, total, 1).map(function (d) {\n    return {};\n  }); // collect sample data for each field\n\n  fields.forEach(function (field, fieldIdx) {\n    // data counter\n    var i = 0; // sample counter\n\n    var j = 0;\n    while (j < total) {\n      if (i >= rows.length) {\n        // if depleted data pool\n        sample[j][field] = null;\n        j++;\n      } else if ((0, _dataUtils.notNullorUndefined)(rows[i][fieldIdx])) {\n        var value = rows[i][fieldIdx];\n        sample[j][field] = typeof value === 'string' ? value.trim() : value;\n        j++;\n        i++;\n      } else {\n        i++;\n      }\n    }\n  });\n  return sample;\n}\n/**\n * Convert falsy value in csv including `'', 'null', 'NULL', 'Null', 'NaN'` to `null`,\n * so that type-analyzer won't detect it as string\n *\n * @param {Array<Array>} rows\n */\n\nfunction cleanUpFalsyCsvValue(rows) {\n  var re = new RegExp(CSV_NULLS, 'g');\n  for (var i = 0; i < rows.length; i++) {\n    for (var j = 0; j < rows[i].length; j++) {\n      // analyzer will set any fields to 'string' if there are empty values\n      // which will be parsed as '' by d3.csv\n      // here we parse empty data as null\n      // TODO: create warning when deltect `CSV_NULLS` in the data\n      if (typeof rows[i][j] === 'string' && rows[i][j].match(re)) {\n        rows[i][j] = null;\n      }\n    }\n  }\n}\n/**\n * Process uploaded csv file to parse value by field type\n *\n * @param rows\n * @param geoFieldIdx field index\n * @param field\n * @param i\n * @type {typeof import('./data-processor').parseCsvRowsByFieldType}\n */\n\nfunction parseCsvRowsByFieldType(rows, geoFieldIdx, field, i) {\n  var parser = PARSE_FIELD_VALUE_FROM_STRING[field.type];\n  if (parser) {\n    // check first not null value of it's already parsed\n    var first = rows.find(function (r) {\n      return (0, _dataUtils.notNullorUndefined)(r[i]);\n    });\n    if (!first || parser.valid(first[i], field)) {\n      return;\n    }\n    rows.forEach(function (row) {\n      // parse string value based on field type\n      if (row[i] !== null) {\n        row[i] = parser.parse(row[i], field);\n        if (geoFieldIdx > -1 && row[geoFieldIdx] && row[geoFieldIdx].properties) {\n          row[geoFieldIdx].properties[field.name] = row[i];\n        }\n      }\n    });\n  }\n}\n/**\n * Analyze field types from data in `string` format, e.g. uploaded csv.\n * Assign `type`, `fieldIdx` and `format` (timestamp only) to each field\n *\n * @param data array of row object\n * @param fieldOrder array of field names as string\n * @returns formatted fields\n * @type {typeof import('./data-processor').getFieldsFromData}\n * @public\n * @example\n *\n * import {getFieldsFromData} from 'kepler.gl/processors';\n * const data = [{\n *   time: '2016-09-17 00:09:55',\n *   value: '4',\n *   surge: '1.2',\n *   isTrip: 'true',\n *   zeroOnes: '0'\n * }, {\n *   time: '2016-09-17 00:30:08',\n *   value: '3',\n *   surge: null,\n *   isTrip: 'false',\n *   zeroOnes: '1'\n * }, {\n *   time: null,\n *   value: '2',\n *   surge: '1.3',\n *   isTrip: null,\n *   zeroOnes: '1'\n * }];\n *\n * const fieldOrder = ['time', 'value', 'surge', 'isTrip', 'zeroOnes'];\n * const fields = getFieldsFromData(data, fieldOrder);\n * // fields = [\n * // {name: 'time', format: 'YYYY-M-D H:m:s', fieldIdx: 1, type: 'timestamp'},\n * // {name: 'value', format: '', fieldIdx: 4, type: 'integer'},\n * // {name: 'surge', format: '', fieldIdx: 5, type: 'real'},\n * // {name: 'isTrip', format: '', fieldIdx: 6, type: 'boolean'},\n * // {name: 'zeroOnes', format: '', fieldIdx: 7, type: 'integer'}];\n *\n */\n\nfunction getFieldsFromData(data, fieldOrder) {\n  // add a check for epoch timestamp\n  var metadata = _typeAnalyzer.Analyzer.computeColMeta(data, [{\n    regex: /.*geojson|all_points/g,\n    dataType: 'GEOMETRY'\n  }, {\n    regex: /.*census/g,\n    dataType: 'STRING'\n  }], {\n    ignoredDataTypes: IGNORE_DATA_TYPES\n  });\n  var _renameDuplicateField = renameDuplicateFields(fieldOrder),\n    fieldByIndex = _renameDuplicateField.fieldByIndex;\n  var result = fieldOrder.map(function (field, index) {\n    var name = fieldByIndex[index];\n    var fieldMeta = metadata.find(function (m) {\n      return m.key === field;\n    });\n    var _ref2 = fieldMeta || {},\n      type = _ref2.type,\n      format = _ref2.format;\n    return {\n      name: name,\n      id: name,\n      displayName: name,\n      format: format,\n      fieldIdx: index,\n      type: analyzerTypeToFieldType(type),\n      analyzerType: type,\n      valueAccessor: function valueAccessor(dc) {\n        return function (d) {\n          return dc.valueAt(d.index, index);\n        };\n      }\n    };\n  }); // @ts-ignore\n\n  return result;\n}\n/**\n * pass in an array of field names, rename duplicated one\n * and return a map from old field index to new name\n *\n * @param {Array} fieldOrder\n * @returns {Object} new field name by index\n */\n\nfunction renameDuplicateFields(fieldOrder) {\n  return fieldOrder.reduce(function (accu, field, i) {\n    var allNames = accu.allNames;\n    var fieldName = field; // add a counter to duplicated names\n\n    if (allNames.includes(field)) {\n      var counter = 0;\n      while (allNames.includes(\"\".concat(field, \"-\").concat(counter))) {\n        counter++;\n      }\n      fieldName = \"\".concat(field, \"-\").concat(counter);\n    }\n    accu.fieldByIndex[i] = fieldName;\n    accu.allNames.push(fieldName);\n    return accu;\n  }, {\n    allNames: [],\n    fieldByIndex: {}\n  });\n}\n/**\n * Convert type-analyzer output to kepler.gl field types\n *\n * @param aType\n * @returns corresponding type in `ALL_FIELD_TYPES`\n * @type {typeof import('./data-processor').analyzerTypeToFieldType}}\n */\n\n/* eslint-disable complexity */\n\nfunction analyzerTypeToFieldType(aType) {\n  var DATE = _typeAnalyzer.DATA_TYPES.DATE,\n    TIME = _typeAnalyzer.DATA_TYPES.TIME,\n    DATETIME = _typeAnalyzer.DATA_TYPES.DATETIME,\n    NUMBER = _typeAnalyzer.DATA_TYPES.NUMBER,\n    INT = _typeAnalyzer.DATA_TYPES.INT,\n    FLOAT = _typeAnalyzer.DATA_TYPES.FLOAT,\n    BOOLEAN = _typeAnalyzer.DATA_TYPES.BOOLEAN,\n    STRING = _typeAnalyzer.DATA_TYPES.STRING,\n    GEOMETRY = _typeAnalyzer.DATA_TYPES.GEOMETRY,\n    GEOMETRY_FROM_STRING = _typeAnalyzer.DATA_TYPES.GEOMETRY_FROM_STRING,\n    PAIR_GEOMETRY_FROM_STRING = _typeAnalyzer.DATA_TYPES.PAIR_GEOMETRY_FROM_STRING,\n    ZIPCODE = _typeAnalyzer.DATA_TYPES.ZIPCODE,\n    ARRAY = _typeAnalyzer.DATA_TYPES.ARRAY,\n    OBJECT = _typeAnalyzer.DATA_TYPES.OBJECT; // TODO: un recognized types\n  // CURRENCY PERCENT NONE\n\n  switch (aType) {\n    case DATE:\n      return _defaultSettings.ALL_FIELD_TYPES.date;\n    case TIME:\n    case DATETIME:\n      return _defaultSettings.ALL_FIELD_TYPES.timestamp;\n    case FLOAT:\n      return _defaultSettings.ALL_FIELD_TYPES.real;\n    case INT:\n      return _defaultSettings.ALL_FIELD_TYPES.integer;\n    case BOOLEAN:\n      return _defaultSettings.ALL_FIELD_TYPES[\"boolean\"];\n    case GEOMETRY:\n    case GEOMETRY_FROM_STRING:\n    case PAIR_GEOMETRY_FROM_STRING:\n    case ARRAY:\n    case OBJECT:\n      // TODO: create a new data type for objects and arrays\n      return _defaultSettings.ALL_FIELD_TYPES.geojson;\n    case NUMBER:\n    case STRING:\n    case ZIPCODE:\n      return _defaultSettings.ALL_FIELD_TYPES.string;\n    default:\n      _window.console.warn(\"Unsupported analyzer type: \".concat(aType));\n      return _defaultSettings.ALL_FIELD_TYPES.string;\n  }\n}\n/* eslint-enable complexity */\n\n/**\n * Process data where each row is an object, output can be passed to [`addDataToMap`](../actions/actions.md#adddatatomap)\n * NOTE: This function may mutate input.\n * @param rawData an array of row object, each object should have the same number of keys\n * @returns dataset containing `fields` and `rows`\n * @type {typeof import('./data-processor').processRowObject}\n * @public\n * @example\n * import {addDataToMap} from 'kepler.gl/actions';\n * import {processRowObject} from 'kepler.gl/processors';\n *\n * const data = [\n *  {lat: 31.27, lng: 127.56, value: 3},\n *  {lat: 31.22, lng: 126.26, value: 1}\n * ];\n *\n * dispatch(addDataToMap({\n *  datasets: {\n *    info: {label: 'My Data', id: 'my_data'},\n *    data: processRowObject(data)\n *  }\n * }));\n */\n\nfunction processRowObject(rawData) {\n  if (!Array.isArray(rawData) || !rawData.length) {\n    return null;\n  }\n  var keys = Object.keys(rawData[0]);\n  var rows = rawData.map(function (d) {\n    return keys.map(function (key) {\n      return d[key];\n    });\n  }); // row object an still contain values like `Null` or `N/A`\n\n  cleanUpFalsyCsvValue(rows);\n  return processCsvData(rows, keys);\n}\n/**\n * Process GeoJSON [`FeatureCollection`](http://wiki.geojson.org/GeoJSON_draft_version_6#FeatureCollection),\n * output a data object with `{fields: [], rows: []}`.\n * The data object can be wrapped in a `dataset` and passed to [`addDataToMap`](../actions/actions.md#adddatatomap)\n * NOTE: This function may mutate input.\n *\n * @param  rawData raw geojson feature collection\n * @returns  dataset containing `fields` and `rows`\n * @type {typeof import('./data-processor').processGeojson}\n * @public\n * @example\n * import {addDataToMap} from 'kepler.gl/actions';\n * import {processGeojson} from 'kepler.gl/processors';\n *\n * const geojson = {\n * \t\"type\" : \"FeatureCollection\",\n * \t\"features\" : [{\n * \t\t\"type\" : \"Feature\",\n * \t\t\"properties\" : {\n * \t\t\t\"capacity\" : \"10\",\n * \t\t\t\"type\" : \"U-Rack\"\n * \t\t},\n * \t\t\"geometry\" : {\n * \t\t\t\"type\" : \"Point\",\n * \t\t\t\"coordinates\" : [ -71.073283, 42.417500 ]\n * \t\t}\n * \t}]\n * };\n *\n * dispatch(addDataToMap({\n *  datasets: {\n *    info: {\n *      label: 'Sample Taxi Trips in New York City',\n *      id: 'test_trip_data'\n *    },\n *    data: processGeojson(geojson)\n *  }\n * }));\n */\n\nfunction processGeojson(rawData) {\n  var normalizedGeojson = (0, _geojsonNormalize[\"default\"])(rawData);\n  if (!normalizedGeojson || !Array.isArray(normalizedGeojson.features)) {\n    var error = new Error(\"Read File Failed: File is not a valid GeoJSON. Read more about [supported file format](\".concat(_userGuides.GUIDES_FILE_FORMAT_DOC, \")\"));\n    throw error; // fail to normalize geojson\n  } // getting all feature fields\n\n  var allDataRows = [];\n  for (var i = 0; i < normalizedGeojson.features.length; i++) {\n    var f = normalizedGeojson.features[i];\n    if (f.geometry) {\n      allDataRows.push(_objectSpread({\n        // add feature to _geojson field\n        _geojson: f\n      }, f.properties || {}));\n    }\n  } // get all the field\n\n  var fields = allDataRows.reduce(function (prev, curr) {\n    Object.keys(curr).forEach(function (key) {\n      if (!prev.includes(key)) {\n        prev.push(key);\n      }\n    });\n    return prev;\n  }, []); // make sure each feature has exact same fields\n\n  allDataRows.forEach(function (d) {\n    fields.forEach(function (f) {\n      if (!(f in d)) {\n        d[f] = null;\n        d._geojson.properties[f] = null;\n      }\n    });\n  });\n  return processRowObject(allDataRows);\n}\n/**\n * On export data to csv\n * @param {import('utils/table-utils/data-container-interface').DataContainerInterface} dataContainer\n * @param {Array<Object>} fields `dataset.fields`\n * @returns {string} csv string\n */\n\nfunction formatCsv(dataContainer, fields) {\n  var columns = fields.map(function (f) {\n    return f.displayName || f.name;\n  });\n  var formattedData = [columns]; // parse geojson object as string\n\n  var _iterator = _createForOfIteratorHelper(dataContainer.rows(true)),\n    _step;\n  try {\n    for (_iterator.s(); !(_step = _iterator.n()).done;) {\n      var row = _step.value;\n      formattedData.push(row.map(function (d, i) {\n        return (0, _dataUtils.parseFieldValue)(d, fields[i].type);\n      }));\n    }\n  } catch (err) {\n    _iterator.e(err);\n  } finally {\n    _iterator.f();\n  }\n  return (0, _d3Dsv.csvFormatRows)(formattedData);\n}\n/**\n * Validate input data, adding missing field types, rename duplicate columns\n * @type {typeof import('./data-processor').validateInputData}\n */\n\nfunction validateInputData(data) {\n  if (!(0, _utils.isPlainObject)(data)) {\n    (0, _assert[\"default\"])('addDataToMap Error: dataset.data cannot be null');\n    return null;\n  } else if (!Array.isArray(data.fields)) {\n    (0, _assert[\"default\"])('addDataToMap Error: expect dataset.data.fields to be an array');\n    return null;\n  } else if (!Array.isArray(data.rows)) {\n    (0, _assert[\"default\"])('addDataToMap Error: expect dataset.data.rows to be an array');\n    return null;\n  }\n  var fields = data.fields,\n    rows = data.rows; // check if all fields has name, format and type\n\n  var allValid = fields.every(function (f, i) {\n    if (!(0, _utils.isPlainObject)(f)) {\n      (0, _assert[\"default\"])(\"fields needs to be an array of object, but find \".concat((0, _typeof2[\"default\"])(f)));\n      fields[i] = {};\n    }\n    if (!f.name) {\n      (0, _assert[\"default\"])(\"field.name is required but missing in \".concat(JSON.stringify(f))); // assign a name\n\n      fields[i].name = \"column_\".concat(i);\n    }\n    if (!_defaultSettings.ALL_FIELD_TYPES[f.type]) {\n      (0, _assert[\"default\"])(\"unknown field type \".concat(f.type));\n      return false;\n    }\n    if (!fields.every(function (field) {\n      return field.analyzerType;\n    })) {\n      (0, _assert[\"default\"])('field missing analyzerType');\n      return false;\n    } // check time format is correct based on first 10 not empty element\n\n    if (f.type === _defaultSettings.ALL_FIELD_TYPES.timestamp) {\n      var sample = findNonEmptyRowsAtField(rows, i, 10).map(function (r) {\n        return {\n          ts: r[i]\n        };\n      });\n      var analyzedType = _typeAnalyzer.Analyzer.computeColMeta(sample)[0];\n      return analyzedType && analyzedType.category === 'TIME' && analyzedType.format === f.format;\n    }\n    return true;\n  });\n  if (allValid) {\n    return {\n      rows: rows,\n      fields: fields\n    };\n  } // if any field has missing type, recalculate it for everyone\n  // because we simply lost faith in humanity\n\n  var sampleData = getSampleForTypeAnalyze({\n    fields: fields.map(function (f) {\n      return f.name;\n    }),\n    rows: rows\n  });\n  var fieldOrder = fields.map(function (f) {\n    return f.name;\n  });\n  var meta = getFieldsFromData(sampleData, fieldOrder);\n  var updatedFields = fields.map(function (f, i) {\n    return _objectSpread(_objectSpread({}, f), {}, {\n      type: meta[i].type,\n      format: meta[i].format,\n      analyzerType: meta[i].analyzerType\n    });\n  });\n  return {\n    fields: updatedFields,\n    rows: rows\n  };\n}\nfunction findNonEmptyRowsAtField(rows, fieldIdx, total) {\n  var sample = [];\n  var i = 0;\n  while (sample.length < total && i < rows.length) {\n    if ((0, _dataUtils.notNullorUndefined)(rows[i][fieldIdx])) {\n      sample.push(rows[i]);\n    }\n    i++;\n  }\n  return sample;\n}\n/**\n * Process saved kepler.gl json to be pass to [`addDataToMap`](../actions/actions.md#adddatatomap).\n * The json object should contain `datasets` and `config`.\n * @param {Object} rawData\n * @param {Array} rawData.datasets\n * @param {Object} rawData.config\n * @returns {Object} datasets and config `{datasets: {}, config: {}}`\n * @public\n * @example\n * import {addDataToMap} from 'kepler.gl/actions';\n * import {processKeplerglJSON} from 'kepler.gl/processors';\n *\n * dispatch(addDataToMap(processKeplerglJSON(keplerGlJson)));\n */\n\nfunction processKeplerglJSON(rawData) {\n  return rawData ? _schemas[\"default\"].load(rawData.datasets, rawData.config) : null;\n}\n/**\n * Parse a single or an array of datasets saved using kepler.gl schema\n * @param {Array | Array<Object>} rawData\n */\n\nfunction processKeplerglDataset(rawData) {\n  if (!rawData) {\n    return null;\n  }\n  var results = _schemas[\"default\"].parseSavedData((0, _utils.toArray)(rawData));\n  if (!results) {\n    return null;\n  }\n  return Array.isArray(rawData) ? results : results[0];\n}\nvar DATASET_HANDLERS = (_DATASET_HANDLERS = {}, (0, _defineProperty2[\"default\"])(_DATASET_HANDLERS, _defaultSettings.DATASET_FORMATS.row, processRowObject), (0, _defineProperty2[\"default\"])(_DATASET_HANDLERS, _defaultSettings.DATASET_FORMATS.geojson, processGeojson), (0, _defineProperty2[\"default\"])(_DATASET_HANDLERS, _defaultSettings.DATASET_FORMATS.csv, processCsvData), (0, _defineProperty2[\"default\"])(_DATASET_HANDLERS, _defaultSettings.DATASET_FORMATS.keplergl, processKeplerglDataset), _DATASET_HANDLERS);\nexports.DATASET_HANDLERS = DATASET_HANDLERS;\nvar Processors = {\n  processGeojson: processGeojson,\n  processCsvData: processCsvData,\n  processRowObject: processRowObject,\n  processKeplerglJSON: processKeplerglJSON,\n  processKeplerglDataset: processKeplerglDataset,\n  analyzerTypeToFieldType: analyzerTypeToFieldType,\n  getFieldsFromData: getFieldsFromData,\n  parseCsvRowsByFieldType: parseCsvRowsByFieldType,\n  formatCsv: formatCsv\n};\nexports.Processors = Processors;","map":{"version":3,"sources":["../../src/processors/data-processor.js"],"names":["ACCEPTED_ANALYZER_TYPES","AnalyzerDATA_TYPES","DATE","TIME","DATETIME","NUMBER","INT","FLOAT","BOOLEAN","STRING","GEOMETRY","GEOMETRY_FROM_STRING","PAIR_GEOMETRY_FROM_STRING","ZIPCODE","ARRAY","OBJECT","CSV_NULLS","IGNORE_DATA_TYPES","keys","filter","includes","type","PARSE_FIELD_VALUE_FROM_STRING","ALL_FIELD_TYPES","valid","d","parse","integer","parseInt","timestamp","field","format","Number","real","parseFloat","processCsvData","rawData","header","rows","headerRow","parsedRows","Array","isArray","length","Error","slice","cleanUpFalsyCsvValue","sample","getSampleForTypeAnalyze","fields","getFieldsFromData","parseRowsByFields","geojsonFieldIdx","findIndex","f","name","forEach","parseCsvRowsByFieldType","bind","sampleCount","total","Math","min","map","fieldIdx","i","j","value","trim","re","RegExp","match","geoFieldIdx","parser","first","find","r","row","properties","data","fieldOrder","metadata","computeColMeta","regex","dataType","ignoredDataTypes","fieldByIndex","renameDuplicateFields","result","index","fieldMeta","m","key","id","displayName","analyzerTypeToFieldType","analyzerType","valueAccessor","dc","valueAt","reduce","accu","allNames","fieldName","counter","push","aType","date","geojson","string","globalConsole","warn","processRowObject","Object","processGeojson","normalizedGeojson","features","error","GUIDES_FILE_FORMAT_DOC","allDataRows","geometry","_geojson","prev","curr","formatCsv","dataContainer","columns","formattedData","validateInputData","allValid","every","JSON","stringify","ts","analyzedType","Analyzer","category","sampleData","meta","updatedFields","findNonEmptyRowsAtField","processKeplerglJSON","KeplerGlSchema","load","datasets","config","processKeplerglDataset","results","parseSavedData","DATASET_HANDLERS","DATASET_FORMATS","csv","keplergl","Processors"],"mappings":";;;;;;;;;;;;;;;;;;;;;;AAoBA,IAAA,MAAA,GAAA,OAAA,CAAA,QAAA,CAAA;AACA,IAAA,QAAA,GAAA,OAAA,CAAA,UAAA,CAAA;AACA,IAAA,OAAA,GAAA,OAAA,CAAA,eAAA,CAAA;AACA,IAAA,OAAA,GAAA,sBAAA,CAAA,OAAA,CAAA,QAAA,CAAA,CAAA;AACA,IAAA,aAAA,GAAA,OAAA,CAAA,eAAA,CAAA;AACA,IAAA,iBAAA,GAAA,sBAAA,CAAA,OAAA,CAAA,2BAAA,CAAA,CAAA;AACA,IAAA,gBAAA,GAAA,OAAA,CAAA,+BAAA,CAAA;AACA,IAAA,UAAA,GAAA,OAAA,CAAA,qBAAA,CAAA;AACA,IAAA,QAAA,GAAA,sBAAA,CAAA,OAAA,CAAA,YAAA,CAAA,CAAA;AACA,IAAA,WAAA,GAAA,OAAA,CAAA,0BAAA,CAAA;AACA,IAAA,MAAA,GAAA,OAAA,CAAA,gBAAA,CAAA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAEO,IAAMA,uBAAuB,GAAG,CACrCC,aAAAA,CAAAA,UAAAA,CAAmBC,IADkB,EAErCD,aAAAA,CAAAA,UAAAA,CAAmBE,IAFkB,EAGrCF,aAAAA,CAAAA,UAAAA,CAAmBG,QAHkB,EAIrCH,aAAAA,CAAAA,UAAAA,CAAmBI,MAJkB,EAKrCJ,aAAAA,CAAAA,UAAAA,CAAmBK,GALkB,EAMrCL,aAAAA,CAAAA,UAAAA,CAAmBM,KANkB,EAOrCN,aAAAA,CAAAA,UAAAA,CAAmBO,OAPkB,EAQrCP,aAAAA,CAAAA,UAAAA,CAAmBQ,MARkB,EASrCR,aAAAA,CAAAA,UAAAA,CAAmBS,QATkB,EAUrCT,aAAAA,CAAAA,UAAAA,CAAmBU,oBAVkB,EAWrCV,aAAAA,CAAAA,UAAAA,CAAmBW,yBAXkB,EAYrCX,aAAAA,CAAAA,UAAAA,CAAmBY,OAZkB,EAarCZ,aAAAA,CAAAA,UAAAA,CAAmBa,KAbkB,EAcrCb,aAAAA,CAAAA,UAAAA,CAAmBc,MAdkB,CAAhC,C,CAiBP;AACA;AACA;;;AACO,IAAMC,SAAS,GAAG,8BAAlB;;AAEP,IAAMC,iBAAiB,GAAG,MAAM,CAACC,IAAP,CAAYjB,aAAAA,CAAAA,UAAZ,CAAA,CAAgCkB,MAAhC,CACxB,UAAA,IAAI,EAAA;EAAA,OAAI,CAACnB,uBAAuB,CAACoB,QAAxBpB,CAAiCqB,IAAjCrB,CAAL;AAAA,CADoB,CAA1B;AAIO,IAAMsB,6BAA6B,IAAA,qBAAA,GAAA,CAAA,CAAA,EAAA,CAAA,CAAA,EAAA,gBAAA,CAAA,SAAA,CAAA,EAAA,qBAAA,EACvCC,gBAAAA,CAAAA,eAAAA,CAAAA,SAAAA,CADuC,EACb;EACzBC,KAAK,EAAE,SAAA,KAAA,CAAA,CAAC,EAAA;IAAA,OAAI,OAAOC,CAAP,KAAa,SAAjB;EAAA,CADiB;EAEzBC,KAAK,EAAE,SAAA,KAAA,CAAA,CAAC,EAAA;IAAA,OAAID,CAAC,KAAK,MAANA,IAAgBA,CAAC,KAAK,MAAtBA,IAAgCA,CAAC,KAAK,MAAtCA,IAAgDA,CAAC,KAAK,GAA1D;EAAA;AAFiB,CADa,CAAA,EAAA,CAAA,CAAA,EAAA,gBAAA,CAAA,SAAA,CAAA,EAAA,qBAAA,EAKvCF,gBAAAA,CAAAA,eAAAA,CAAgBI,OALuB,EAKb;EACzBH,KAAK,EAAE,SAAA,KAAA,CAAA,CAAC,EAAA;IAAA,OAAII,QAAQ,CAACH,CAAD,EAAI,EAAJ,CAARG,KAAoBH,CAAxB;EAAA,CADiB;EAEzBC,KAAK,EAAE,SAAA,KAAA,CAAA,CAAC,EAAA;IAAA,OAAIE,QAAQ,CAACH,CAAD,EAAI,EAAJ,CAAZ;EAAA;AAFiB,CALa,CAAA,EAAA,CAAA,CAAA,EAAA,gBAAA,CAAA,SAAA,CAAA,EAAA,qBAAA,EASvCF,gBAAAA,CAAAA,eAAAA,CAAgBM,SATuB,EASX;EAC3BL,KAAK,EAAE,SAAA,KAAA,CAACC,CAAD,EAAIK,KAAJ,EAAA;IAAA,OACL,CAAC,GAAD,EAAM,GAAN,CAAA,CAAWV,QAAX,CAAoBU,KAAK,CAACC,MAA1B,CAAA,GAAoC,OAAON,CAAP,KAAa,QAAjD,GAA4D,OAAOA,CAAP,KAAa,QADpE;EAAA,CADoB;EAG3BC,KAAK,EAAE,SAAA,KAAA,CAACD,CAAD,EAAIK,KAAJ,EAAA;IAAA,OAAe,CAAC,GAAD,EAAM,GAAN,CAAA,CAAWV,QAAX,CAAoBU,KAAK,CAACC,MAA1B,CAAA,GAAoCC,MAAM,CAACP,CAAD,CAA1C,GAAgDA,CAA/D;EAAA;AAHoB,CATW,CAAA,EAAA,CAAA,CAAA,EAAA,gBAAA,CAAA,SAAA,CAAA,EAAA,qBAAA,EAcvCF,gBAAAA,CAAAA,eAAAA,CAAgBU,IAduB,EAchB;EACtBT,KAAK,EAAE,SAAA,KAAA,CAAA,CAAC,EAAA;IAAA,OAAIU,UAAU,CAACT,CAAD,CAAVS,KAAkBT,CAAtB;EAAA,CADc;EAEtB;EACAC,KAAK,EAAEQ;AAHe,CAdgB,CAAA,EAAA,qBAAA,CAAnC;AAqBP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACO,SAASC,cAAT,CAAwBC,OAAxB,EAAiCC,MAAjC,EAAyC;EAC9C,IAAIC,IAAJ;EACA,IAAIC,SAAJ;EAEA,IAAI,OAAOH,OAAP,KAAmB,QAAvB,EAAiC;IAC/B,IAAMI,WAAU,GAAG,CAAA,CAAA,EAAA,MAAA,CAAA,YAAA,EAAaJ,OAAb,CAAnB;IAEA,IAAI,CAACK,KAAK,CAACC,OAAND,CAAcD,WAAdC,CAAD,IAA8BD,WAAU,CAACG,MAAXH,GAAoB,CAAtD,EAAyD;MACvD;MACA,MAAM,IAAII,KAAJ,CAAU,uCAAV,CAAN;IACD;IACDL,SAAS,GAAGC,WAAU,CAAC,CAAD,CAAtBD;IACAD,IAAI,GAAGE,WAAU,CAACK,KAAXL,CAAiB,CAAjBA,CAAPF;EACD,CATD,MASO,IAAIG,KAAK,CAACC,OAAND,CAAcL,OAAdK,CAAAA,IAA0BL,OAAO,CAACO,MAAtC,EAA8C;IACnDL,IAAI,GAAGF,OAAPE;IACAC,SAAS,GAAGF,MAAZE;IAEA,IAAI,CAACE,KAAK,CAACC,OAAND,CAAcF,SAAdE,CAAL,EAA+B;MAC7B;MACA;MACAF,SAAS,GAAGH,OAAO,CAAC,CAAD,CAAnBG;MACAD,IAAI,GAAGF,OAAO,CAACS,KAART,CAAc,CAAdA,CAAPE;IACD;EACF;EAED,IAAI,CAACA,IAAD,IAAS,CAACC,SAAd,EAAyB;IACvB,MAAM,IAAIK,KAAJ,CAAU,wCAAV,CAAN;EACD,CA3B6C,CA6B9C;EACA;;EAEAE,oBAAoB,CAACR,IAAD,CAApBQ,CAhC8C,CAiC9C;EACA;;EACA,IAAMC,MAAM,GAAGC,uBAAuB,CAAC;IAACC,MAAM,EAAEV,SAAT;IAAoBD,IAAI,EAAJA;EAApB,CAAD,CAAtC;EACA,IAAMW,MAAM,GAAGC,iBAAiB,CAACH,MAAD,EAASR,SAAT,CAAhC;EACA,IAAMC,UAAU,GAAGW,iBAAiB,CAACb,IAAD,EAAOW,MAAP,CAApC;EAEA,OAAO;IAACA,MAAM,EAANA,MAAD;IAASX,IAAI,EAAEE;EAAf,CAAP;AACD;AAED;AACA;AACA;AACA;AACA;;AACO,SAASW,iBAAT,CAA2Bb,IAA3B,EAAiCW,MAAjC,EAAyC;EAC9C;EACA,IAAMG,eAAe,GAAG,MAAM,CAACC,SAAP,CAAiB,UAAA,CAAC,EAAA;IAAA,OAAIC,CAAC,CAACC,IAAFD,KAAW,UAAf;EAAA,CAAlB,CAAxB;EACAL,MAAM,CAACO,OAAPP,CAAeQ,uBAAuB,CAACC,IAAxBD,CAA6B,IAA7BA,EAAmCnB,IAAnCmB,EAAyCL,eAAzCK,CAAfR,CAAAA;EAEA,OAAOX,IAAP;AACD;AACD;AACA;AACA;AACA;AACA;;AACO,SAASU,uBAAT,CAAA,IAAA,EAAmE;EAAA,IAAjCC,MAAiC,GAAA,IAAA,CAAjCA,MAAiC;IAAzBX,IAAyB,GAAA,IAAA,CAAzBA,IAAyB;IAAA,gBAAA,GAAA,IAAA,CAAnBqB,WAAmB;IAAnBA,WAAmB,GAAA,gBAAA,KAAA,KAAA,CAAA,GAAL,EAAK,GAAA,gBAAA;EACxE,IAAMC,KAAK,GAAGC,IAAI,CAACC,GAALD,CAASF,WAATE,EAAsBvB,IAAI,CAACK,MAA3BkB,CAAd,CADwE,CAExE;;EACA,IAAMd,MAAM,GAAG,CAAA,CAAA,EAAA,QAAA,CAAA,KAAA,EAAM,CAAN,EAASa,KAAT,EAAgB,CAAhB,CAAA,CAAmBG,GAAnB,CAAuB,UAAA,CAAC,EAAA;IAAA,OAAK,CAAA,CAAL;EAAA,CAAxB,CAAf,CAHwE,CAKxE;;EACAd,MAAM,CAACO,OAAPP,CAAe,UAACnB,KAAD,EAAQkC,QAAR,EAAqB;IAClC;IACA,IAAIC,CAAC,GAAG,CAAR,CAFkC,CAGlC;;IACA,IAAIC,CAAC,GAAG,CAAR;IAEA,OAAOA,CAAC,GAAGN,KAAX,EAAkB;MAChB,IAAIK,CAAC,IAAI3B,IAAI,CAACK,MAAd,EAAsB;QACpB;QACAI,MAAM,CAACmB,CAAD,CAANnB,CAAUjB,KAAViB,CAAAA,GAAmB,IAAnBA;QACAmB,CAAC,EAAA;MACF,CAJD,MAIO,IAAI,CAAA,CAAA,EAAA,UAAA,CAAA,kBAAA,EAAmB5B,IAAI,CAAC2B,CAAD,CAAJ3B,CAAQ0B,QAAR1B,CAAnB,CAAJ,EAA2C;QAChD,IAAM6B,KAAK,GAAG7B,IAAI,CAAC2B,CAAD,CAAJ3B,CAAQ0B,QAAR1B,CAAd;QACAS,MAAM,CAACmB,CAAD,CAANnB,CAAUjB,KAAViB,CAAAA,GAAmB,OAAOoB,KAAP,KAAiB,QAAjB,GAA4BA,KAAK,CAACC,IAAND,EAA5B,GAA2CA,KAA9DpB;QACAmB,CAAC,EAAA;QACDD,CAAC,EAAA;MACF,CALM,MAKA;QACLA,CAAC,EAAA;MACF;IACF;EACF,CApBDhB,CAAAA;EAsBA,OAAOF,MAAP;AACD;AAED;AACA;AACA;AACA;AACA;AACA;;AACA,SAASD,oBAAT,CAA8BR,IAA9B,EAAoC;EAClC,IAAM+B,EAAE,GAAG,IAAIC,MAAJ,CAAWtD,SAAX,EAAsB,GAAtB,CAAX;EACA,KAAK,IAAIiD,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAG3B,IAAI,CAACK,MAAzB,EAAiCsB,CAAC,EAAlC,EAAsC;IACpC,KAAK,IAAIC,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAG5B,IAAI,CAAC2B,CAAD,CAAJ3B,CAAQK,MAA5B,EAAoCuB,CAAC,EAArC,EAAyC;MACvC;MACA;MACA;MACA;MACA,IAAI,OAAO5B,IAAI,CAAC2B,CAAD,CAAJ3B,CAAQ4B,CAAR5B,CAAP,KAAsB,QAAtB,IAAkCA,IAAI,CAAC2B,CAAD,CAAJ3B,CAAQ4B,CAAR5B,CAAAA,CAAWiC,KAAXjC,CAAiB+B,EAAjB/B,CAAtC,EAA4D;QAC1DA,IAAI,CAAC2B,CAAD,CAAJ3B,CAAQ4B,CAAR5B,CAAAA,GAAa,IAAbA;MACD;IACF;EACF;AACF;AAED;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACO,SAASmB,uBAAT,CAAiCnB,IAAjC,EAAuCkC,WAAvC,EAAoD1C,KAApD,EAA2DmC,CAA3D,EAA8D;EACnE,IAAMQ,MAAM,GAAGnD,6BAA6B,CAACQ,KAAK,CAACT,IAAP,CAA5C;EACA,IAAIoD,MAAJ,EAAY;IACV;IACA,IAAMC,KAAK,GAAG,IAAI,CAACC,IAAL,CAAU,UAAA,CAAC,EAAA;MAAA,OAAI,CAAA,CAAA,EAAA,UAAA,CAAA,kBAAA,EAAmBC,CAAC,CAACX,CAAD,CAApB,CAAJ;IAAA,CAAX,CAAd;IACA,IAAI,CAACS,KAAD,IAAUD,MAAM,CAACjD,KAAPiD,CAAaC,KAAK,CAACT,CAAD,CAAlBQ,EAAuB3C,KAAvB2C,CAAd,EAA6C;MAC3C;IACD;IACDnC,IAAI,CAACkB,OAALlB,CAAa,UAAA,GAAG,EAAI;MAClB;MACA,IAAIuC,GAAG,CAACZ,CAAD,CAAHY,KAAW,IAAf,EAAqB;QACnBA,GAAG,CAACZ,CAAD,CAAHY,GAASJ,MAAM,CAAC/C,KAAP+C,CAAaI,GAAG,CAACZ,CAAD,CAAhBQ,EAAqB3C,KAArB2C,CAATI;QACA,IAAIL,WAAW,GAAG,CAAC,CAAfA,IAAoBK,GAAG,CAACL,WAAD,CAAvBA,IAAwCK,GAAG,CAACL,WAAD,CAAHK,CAAiBC,UAA7D,EAAyE;UACvED,GAAG,CAACL,WAAD,CAAHK,CAAiBC,UAAjBD,CAA4B/C,KAAK,CAACyB,IAAlCsB,CAAAA,GAA0CA,GAAG,CAACZ,CAAD,CAA7CY;QACD;MACF;IACF,CARDvC,CAAAA;EASD;AACF;AAED;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACO,SAASY,iBAAT,CAA2B6B,IAA3B,EAAiCC,UAAjC,EAA6C;EAClD;EACA,IAAMC,QAAQ,GAAG,aAAA,CAAA,QAAA,CAASC,cAAT,CACfH,IADe,EAEf,CACE;IAACI,KAAK,EAAE,uBAAR;IAAiCC,QAAQ,EAAE;EAA3C,CADF,EAEE;IAACD,KAAK,EAAE,WAAR;IAAqBC,QAAQ,EAAE;EAA/B,CAFF,CAFe,EAMf;IAACC,gBAAgB,EAAEpE;EAAnB,CANe,CAAjB;EAFkD,IAAA,qBAAA,GAW3BsE,qBAAqB,CAACP,UAAD,CAXM;IAW3CM,YAX2C,GAAA,qBAAA,CAW3CA,YAX2C;EAalD,IAAME,MAAM,GAAG,UAAU,CAACzB,GAAX,CAAe,UAACjC,KAAD,EAAQ2D,KAAR,EAAkB;IAC9C,IAAMlC,IAAI,GAAG+B,YAAY,CAACG,KAAD,CAAzB;IAEA,IAAMC,SAAS,GAAG,QAAQ,CAACf,IAAT,CAAc,UAAA,CAAC,EAAA;MAAA,OAAIgB,CAAC,CAACC,GAAFD,KAAU7D,KAAd;IAAA,CAAf,CAAlB;IAH8C,IAAA,KAAA,GAIvB4D,SAAS,IAAI,CAAA,CAJU;MAIvCrE,IAJuC,GAAA,KAAA,CAIvCA,IAJuC;MAIjCU,MAJiC,GAAA,KAAA,CAIjCA,MAJiC;IAM9C,OAAO;MACLwB,IAAI,EAAJA,IADK;MAELsC,EAAE,EAAEtC,IAFC;MAGLuC,WAAW,EAAEvC,IAHR;MAILxB,MAAM,EAANA,MAJK;MAKLiC,QAAQ,EAAEyB,KALL;MAMLpE,IAAI,EAAE0E,uBAAuB,CAAC1E,IAAD,CANxB;MAOL2E,YAAY,EAAE3E,IAPT;MAQL4E,aAAa,EAAE,SAAA,aAAA,CAAA,EAAE,EAAA;QAAA,OAAI,UAAA,CAAC,EAAI;UACxB,OAAOC,EAAE,CAACC,OAAHD,CAAWzE,CAAC,CAACgE,KAAbS,EAAoBT,KAApBS,CAAP;QACD,CAFgB;MAAA;IARZ,CAAP;EAYD,CAlBc,CAAf,CAbkD,CAiClD;;EACA,OAAOV,MAAP;AACD;AAED;AACA;AACA;AACA;AACA;AACA;AACA;;AACO,SAASD,qBAAT,CAA+BP,UAA/B,EAA2C;EAChD,OAAO,UAAU,CAACoB,MAAX,CACL,UAACC,IAAD,EAAOvE,KAAP,EAAcmC,CAAd,EAAoB;IAAA,IACXqC,QADW,GACCD,IADD,CACXC,QADW;IAElB,IAAIC,SAAS,GAAGzE,KAAhB,CAFkB,CAIlB;;IACA,IAAIwE,QAAQ,CAAClF,QAATkF,CAAkBxE,KAAlBwE,CAAJ,EAA8B;MAC5B,IAAIE,OAAO,GAAG,CAAd;MACA,OAAOF,QAAQ,CAAClF,QAATkF,CAAAA,EAAAA,CAAAA,MAAAA,CAAqBxE,KAArBwE,EAAAA,GAAAA,CAAAA,CAAAA,MAAAA,CAA8BE,OAA9BF,CAAAA,CAAP,EAAiD;QAC/CE,OAAO,EAAA;MACR;MACDD,SAAS,GAAA,EAAA,CAAA,MAAA,CAAMzE,KAAN,EAAA,GAAA,CAAA,CAAA,MAAA,CAAe0E,OAAf,CAATD;IACD;IAEDF,IAAI,CAACf,YAALe,CAAkBpC,CAAlBoC,CAAAA,GAAuBE,SAAvBF;IACAA,IAAI,CAACC,QAALD,CAAcI,IAAdJ,CAAmBE,SAAnBF,CAAAA;IAEA,OAAOA,IAAP;EACD,CAlBI,EAmBL;IAACC,QAAQ,EAAE,EAAX;IAAehB,YAAY,EAAE,CAAA;EAA7B,CAnBK,CAAP;AAqBD;AAED;AACA;AACA;AACA;AACA;AACA;AACA;;AACA;;AACO,SAASS,uBAAT,CAAiCW,KAAjC,EAAwC;EAAA,IAE3CxG,IAF2C,GAgBzCD,aAAAA,CAAAA,UAhByC,CAE3CC,IAF2C;IAG3CC,IAH2C,GAgBzCF,aAAAA,CAAAA,UAhByC,CAG3CE,IAH2C;IAI3CC,QAJ2C,GAgBzCH,aAAAA,CAAAA,UAhByC,CAI3CG,QAJ2C;IAK3CC,MAL2C,GAgBzCJ,aAAAA,CAAAA,UAhByC,CAK3CI,MAL2C;IAM3CC,GAN2C,GAgBzCL,aAAAA,CAAAA,UAhByC,CAM3CK,GAN2C;IAO3CC,KAP2C,GAgBzCN,aAAAA,CAAAA,UAhByC,CAO3CM,KAP2C;IAQ3CC,OAR2C,GAgBzCP,aAAAA,CAAAA,UAhByC,CAQ3CO,OAR2C;IAS3CC,MAT2C,GAgBzCR,aAAAA,CAAAA,UAhByC,CAS3CQ,MAT2C;IAU3CC,QAV2C,GAgBzCT,aAAAA,CAAAA,UAhByC,CAU3CS,QAV2C;IAW3CC,oBAX2C,GAgBzCV,aAAAA,CAAAA,UAhByC,CAW3CU,oBAX2C;IAY3CC,yBAZ2C,GAgBzCX,aAAAA,CAAAA,UAhByC,CAY3CW,yBAZ2C;IAa3CC,OAb2C,GAgBzCZ,aAAAA,CAAAA,UAhByC,CAa3CY,OAb2C;IAc3CC,KAd2C,GAgBzCb,aAAAA,CAAAA,UAhByC,CAc3Ca,KAd2C;IAe3CC,MAf2C,GAgBzCd,aAAAA,CAAAA,UAhByC,CAe3Cc,MAf2C,CAAA,CAkB7C;EACA;;EACA,QAAQ2F,KAAR;IACE,KAAKxG,IAAL;MACE,OAAOqB,gBAAAA,CAAAA,eAAAA,CAAgBoF,IAAvB;IACF,KAAKxG,IAAL;IACA,KAAKC,QAAL;MACE,OAAOmB,gBAAAA,CAAAA,eAAAA,CAAgBM,SAAvB;IACF,KAAKtB,KAAL;MACE,OAAOgB,gBAAAA,CAAAA,eAAAA,CAAgBU,IAAvB;IACF,KAAK3B,GAAL;MACE,OAAOiB,gBAAAA,CAAAA,eAAAA,CAAgBI,OAAvB;IACF,KAAKnB,OAAL;MACE,OAAOe,gBAAAA,CAAAA,eAAAA,CAAAA,SAAAA,CAAP;IACF,KAAKb,QAAL;IACA,KAAKC,oBAAL;IACA,KAAKC,yBAAL;IACA,KAAKE,KAAL;IACA,KAAKC,MAAL;MACE;MACA,OAAOQ,gBAAAA,CAAAA,eAAAA,CAAgBqF,OAAvB;IACF,KAAKvG,MAAL;IACA,KAAKI,MAAL;IACA,KAAKI,OAAL;MACE,OAAOU,gBAAAA,CAAAA,eAAAA,CAAgBsF,MAAvB;IACF;MACEC,OAAAA,CAAAA,OAAAA,CAAcC,IAAdD,CAAAA,6BAAAA,CAAAA,MAAAA,CAAiDJ,KAAjDI,CAAAA,CAAAA;MACA,OAAOvF,gBAAAA,CAAAA,eAAAA,CAAgBsF,MAAvB;EAAA;AAEL;AACD;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACO,SAASG,gBAAT,CAA0B5E,OAA1B,EAAmC;EACxC,IAAI,CAACK,KAAK,CAACC,OAAND,CAAcL,OAAdK,CAAD,IAA2B,CAACL,OAAO,CAACO,MAAxC,EAAgD;IAC9C,OAAO,IAAP;EACD;EAED,IAAMzB,IAAI,GAAG+F,MAAM,CAAC/F,IAAP+F,CAAY7E,OAAO,CAAC,CAAD,CAAnB6E,CAAb;EACA,IAAM3E,IAAI,GAAG,OAAO,CAACyB,GAAR,CAAY,UAAA,CAAC,EAAA;IAAA,OAAI,IAAI,CAACA,GAAL,CAAS,UAAA,GAAG,EAAA;MAAA,OAAItC,CAAC,CAACmE,GAAD,CAAL;IAAA,CAAZ,CAAJ;EAAA,CAAb,CAAb,CANwC,CAQxC;;EACA9C,oBAAoB,CAACR,IAAD,CAApBQ;EAEA,OAAOX,cAAc,CAACG,IAAD,EAAOpB,IAAP,CAArB;AACD;AAED;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACO,SAASgG,cAAT,CAAwB9E,OAAxB,EAAiC;EACtC,IAAM+E,iBAAiB,GAAG,CAAA,CAAA,EAAA,iBAAA,CAAA,SAAA,CAAA,EAAU/E,OAAV,CAA1B;EAEA,IAAI,CAAC+E,iBAAD,IAAsB,CAAC1E,KAAK,CAACC,OAAND,CAAc0E,iBAAiB,CAACC,QAAhC3E,CAA3B,EAAsE;IACpE,IAAM4E,KAAK,GAAG,IAAIzE,KAAJ,CAAA,yFAAA,CAAA,MAAA,CAC8E0E,WAAAA,CAAAA,sBAD9E,EAAA,GAAA,CAAA,CAAd;IAGA,MAAMD,KAAN,CAJoE,CAKpE;EACD,CATqC,CAWtC;;EACA,IAAME,WAAW,GAAG,EAApB;EACA,KAAK,IAAItD,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGkD,iBAAiB,CAACC,QAAlBD,CAA2BxE,MAA/C,EAAuDsB,CAAC,EAAxD,EAA4D;IAC1D,IAAMX,CAAC,GAAG6D,iBAAiB,CAACC,QAAlBD,CAA2BlD,CAA3BkD,CAAV;IACA,IAAI7D,CAAC,CAACkE,QAAN,EAAgB;MACdD,WAAW,CAACd,IAAZc,CAAAA,aAAAA,CAAAA;QACE;QACAE,QAAQ,EAAEnE;MAFZiE,CAAAA,EAGMjE,CAAC,CAACwB,UAAFxB,IAAgB,CAAA,CAHtBiE,CAAAA,CAAAA;IAKD;EACF,CAtBqC,CAuBtC;;EACA,IAAMtE,MAAM,GAAG,WAAW,CAACmD,MAAZ,CAAmB,UAACsB,IAAD,EAAOC,IAAP,EAAgB;IAChDV,MAAM,CAAC/F,IAAP+F,CAAYU,IAAZV,CAAAA,CAAkBzD,OAAlByD,CAA0B,UAAA,GAAG,EAAI;MAC/B,IAAI,CAACS,IAAI,CAACtG,QAALsG,CAAc9B,GAAd8B,CAAL,EAAyB;QACvBA,IAAI,CAACjB,IAALiB,CAAU9B,GAAV8B,CAAAA;MACD;IACF,CAJDT,CAAAA;IAKA,OAAOS,IAAP;EACD,CAPc,EAOZ,EAPY,CAAf,CAxBsC,CAiCtC;;EACAH,WAAW,CAAC/D,OAAZ+D,CAAoB,UAAA,CAAC,EAAI;IACvBtE,MAAM,CAACO,OAAPP,CAAe,UAAA,CAAC,EAAI;MAClB,IAAI,EAAEK,CAAC,IAAI7B,CAAP,CAAJ,EAAe;QACbA,CAAC,CAAC6B,CAAD,CAAD7B,GAAO,IAAPA;QACAA,CAAC,CAACgG,QAAFhG,CAAWqD,UAAXrD,CAAsB6B,CAAtB7B,CAAAA,GAA2B,IAA3BA;MACD;IACF,CALDwB,CAAAA;EAMD,CAPDsE,CAAAA;EASA,OAAOP,gBAAgB,CAACO,WAAD,CAAvB;AACD;AAED;AACA;AACA;AACA;AACA;AACA;;AACO,SAASK,SAAT,CAAmBC,aAAnB,EAAkC5E,MAAlC,EAA0C;EAC/C,IAAM6E,OAAO,GAAG,MAAM,CAAC/D,GAAP,CAAW,UAAA,CAAC,EAAA;IAAA,OAAIT,CAAC,CAACwC,WAAFxC,IAAiBA,CAAC,CAACC,IAAvB;EAAA,CAAZ,CAAhB;EACA,IAAMwE,aAAa,GAAG,CAACD,OAAD,CAAtB,CAF+C,CAI/C;;EAJ+C,IAAA,SAAA,GAAA,0BAAA,CAK7BD,aAAa,CAACvF,IAAduF,CAAmB,IAAnBA,CAL6B,CAAA;IAAA,KAAA;EAAA,IAAA;IAK/C,KAAA,SAAA,CAAA,CAAA,EAAA,EAAA,CAAA,CAAA,KAAA,GAAA,SAAA,CAAA,CAAA,EAAA,EAAA,IAAA,GAA4C;MAAA,IAAjChD,GAAiC,GAAA,KAAA,CAAA,KAAA;MAC1CkD,aAAa,CAACtB,IAAdsB,CAAmB,GAAG,CAAChE,GAAJ,CAAQ,UAACtC,CAAD,EAAIwC,CAAJ,EAAA;QAAA,OAAU,CAAA,CAAA,EAAA,UAAA,CAAA,eAAA,EAAgBxC,CAAhB,EAAmBwB,MAAM,CAACgB,CAAD,CAANhB,CAAU5B,IAA7B,CAAV;MAAA,CAAR,CAAnB0G,CAAAA;IACD;EAP8C,CAAA,CAAA,OAAA,GAAA,EAAA;IAAA,SAAA,CAAA,CAAA,CAAA,GAAA,CAAA;EAAA,CAAA,SAAA;IAAA,SAAA,CAAA,CAAA,EAAA;EAAA;EAS/C,OAAO,CAAA,CAAA,EAAA,MAAA,CAAA,aAAA,EAAcA,aAAd,CAAP;AACD;AAED;AACA;AACA;AACA;;AACO,SAASC,iBAAT,CAA2BjD,IAA3B,EAAiC;EACtC,IAAI,CAAC,CAAA,CAAA,EAAA,MAAA,CAAA,aAAA,EAAcA,IAAd,CAAL,EAA0B;IACxB,CAAA,CAAA,EAAA,OAAA,CAAA,SAAA,CAAA,EAAO,iDAAP,CAAA;IACA,OAAO,IAAP;EACD,CAHD,MAGO,IAAI,CAACtC,KAAK,CAACC,OAAND,CAAcsC,IAAI,CAAC9B,MAAnBR,CAAL,EAAiC;IACtC,CAAA,CAAA,EAAA,OAAA,CAAA,SAAA,CAAA,EAAO,+DAAP,CAAA;IACA,OAAO,IAAP;EACD,CAHM,MAGA,IAAI,CAACA,KAAK,CAACC,OAAND,CAAcsC,IAAI,CAACzC,IAAnBG,CAAL,EAA+B;IACpC,CAAA,CAAA,EAAA,OAAA,CAAA,SAAA,CAAA,EAAO,6DAAP,CAAA;IACA,OAAO,IAAP;EACD;EAVqC,IAY/BQ,MAZ+B,GAYf8B,IAZe,CAY/B9B,MAZ+B;IAYvBX,IAZuB,GAYfyC,IAZe,CAYvBzC,IAZuB,CAAA,CActC;;EACA,IAAM2F,QAAQ,GAAG,MAAM,CAACC,KAAP,CAAa,UAAC5E,CAAD,EAAIW,CAAJ,EAAU;IACtC,IAAI,CAAC,CAAA,CAAA,EAAA,MAAA,CAAA,aAAA,EAAcX,CAAd,CAAL,EAAuB;MACrB,CAAA,CAAA,EAAA,OAAA,CAAA,SAAA,CAAA,EAAA,kDAAA,CAAA,MAAA,CAAA,CAAA,CAAA,EAAA,QAAA,CAAA,SAAA,CAAA,EAAiEA,CAAjE,CAAA,CAAA,CAAA;MACAL,MAAM,CAACgB,CAAD,CAANhB,GAAY,CAAA,CAAZA;IACD;IAED,IAAI,CAACK,CAAC,CAACC,IAAP,EAAa;MACX,CAAA,CAAA,EAAA,OAAA,CAAA,SAAA,CAAA,EAAA,wCAAA,CAAA,MAAA,CAAgD4E,IAAI,CAACC,SAALD,CAAe7E,CAAf6E,CAAhD,CAAA,CAAA,CADW,CAEX;;MACAlF,MAAM,CAACgB,CAAD,CAANhB,CAAUM,IAAVN,GAAAA,SAAAA,CAAAA,MAAAA,CAA2BgB,CAA3BhB,CAAAA;IACD;IAED,IAAI,CAAC1B,gBAAAA,CAAAA,eAAAA,CAAgB+B,CAAC,CAACjC,IAAlBE,CAAL,EAA8B;MAC5B,CAAA,CAAA,EAAA,OAAA,CAAA,SAAA,CAAA,EAAA,qBAAA,CAAA,MAAA,CAA6B+B,CAAC,CAACjC,IAA/B,CAAA,CAAA;MACA,OAAO,KAAP;IACD;IAED,IAAI,CAAC,MAAM,CAAC6G,KAAP,CAAa,UAAA,KAAK,EAAA;MAAA,OAAIpG,KAAK,CAACkE,YAAV;IAAA,CAAlB,CAAL,EAAgD;MAC9C,CAAA,CAAA,EAAA,OAAA,CAAA,SAAA,CAAA,EAAO,4BAAP,CAAA;MACA,OAAO,KAAP;IACD,CApBqC,CAsBtC;;IACA,IAAI1C,CAAC,CAACjC,IAAFiC,KAAW/B,gBAAAA,CAAAA,eAAAA,CAAgBM,SAA/B,EAA0C;MACxC,IAAMkB,MAAM,GAAG,uBAAuB,CAACT,IAAD,EAAO2B,CAAP,EAAU,EAAV,CAAvB,CAAqCF,GAArC,CAAyC,UAAA,CAAC,EAAA;QAAA,OAAK;UAACsE,EAAE,EAAEzD,CAAC,CAACX,CAAD;QAAN,CAAL;MAAA,CAA1C,CAAf;MACA,IAAMqE,YAAY,GAAGC,aAAAA,CAAAA,QAAAA,CAASrD,cAATqD,CAAwBxF,MAAxBwF,CAAAA,CAAgC,CAAhCA,CAArB;MACA,OAAOD,YAAY,IAAIA,YAAY,CAACE,QAAbF,KAA0B,MAA1CA,IAAoDA,YAAY,CAACvG,MAAbuG,KAAwBhF,CAAC,CAACvB,MAArF;IACD;IAED,OAAO,IAAP;EACD,CA9BgB,CAAjB;EAgCA,IAAIkG,QAAJ,EAAc;IACZ,OAAO;MAAC3F,IAAI,EAAJA,IAAD;MAAOW,MAAM,EAANA;IAAP,CAAP;EACD,CAjDqC,CAmDtC;EACA;;EACA,IAAMwF,UAAU,GAAGzF,uBAAuB,CAAC;IACzCC,MAAM,EAAE,MAAM,CAACc,GAAP,CAAW,UAAA,CAAC,EAAA;MAAA,OAAIT,CAAC,CAACC,IAAN;IAAA,CAAZ,CADiC;IAEzCjB,IAAI,EAAJA;EAFyC,CAAD,CAA1C;EAIA,IAAM0C,UAAU,GAAG,MAAM,CAACjB,GAAP,CAAW,UAAA,CAAC,EAAA;IAAA,OAAIT,CAAC,CAACC,IAAN;EAAA,CAAZ,CAAnB;EACA,IAAMmF,IAAI,GAAGxF,iBAAiB,CAACuF,UAAD,EAAazD,UAAb,CAA9B;EACA,IAAM2D,aAAa,GAAG,MAAM,CAAC5E,GAAP,CAAW,UAACT,CAAD,EAAIW,CAAJ,EAAA;IAAA,OAAA,aAAA,CAAA,aAAA,CAAA,CAAA,CAAA,EAC5BX,CAD4B,CAAA,EAAA,CAAA,CAAA,EAAA;MAE/BjC,IAAI,EAAEqH,IAAI,CAACzE,CAAD,CAAJyE,CAAQrH,IAFiB;MAG/BU,MAAM,EAAE2G,IAAI,CAACzE,CAAD,CAAJyE,CAAQ3G,MAHe;MAI/BiE,YAAY,EAAE0C,IAAI,CAACzE,CAAD,CAAJyE,CAAQ1C;IAJS,CAAA,CAAA;EAAA,CAAX,CAAtB;EAOA,OAAO;IAAC/C,MAAM,EAAE0F,aAAT;IAAwBrG,IAAI,EAAJA;EAAxB,CAAP;AACD;AAED,SAASsG,uBAAT,CAAiCtG,IAAjC,EAAuC0B,QAAvC,EAAiDJ,KAAjD,EAAwD;EACtD,IAAMb,MAAM,GAAG,EAAf;EACA,IAAIkB,CAAC,GAAG,CAAR;EACA,OAAOlB,MAAM,CAACJ,MAAPI,GAAgBa,KAAhBb,IAAyBkB,CAAC,GAAG3B,IAAI,CAACK,MAAzC,EAAiD;IAC/C,IAAI,CAAA,CAAA,EAAA,UAAA,CAAA,kBAAA,EAAmBL,IAAI,CAAC2B,CAAD,CAAJ3B,CAAQ0B,QAAR1B,CAAnB,CAAJ,EAA2C;MACzCS,MAAM,CAAC0D,IAAP1D,CAAYT,IAAI,CAAC2B,CAAD,CAAhBlB,CAAAA;IACD;IACDkB,CAAC,EAAA;EACF;EACD,OAAOlB,MAAP;AACD;AAED;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACO,SAAS8F,mBAAT,CAA6BzG,OAA7B,EAAsC;EAC3C,OAAOA,OAAO,GAAG0G,QAAAA,CAAAA,SAAAA,CAAAA,CAAeC,IAAfD,CAAoB1G,OAAO,CAAC4G,QAA5BF,EAAsC1G,OAAO,CAAC6G,MAA9CH,CAAH,GAA2D,IAAzE;AACD;AAED;AACA;AACA;AACA;;AACO,SAASI,sBAAT,CAAgC9G,OAAhC,EAAyC;EAC9C,IAAI,CAACA,OAAL,EAAc;IACZ,OAAO,IAAP;EACD;EAED,IAAM+G,OAAO,GAAGL,QAAAA,CAAAA,SAAAA,CAAAA,CAAeM,cAAfN,CAA8B,CAAA,CAAA,EAAA,MAAA,CAAA,OAAA,EAAQ1G,OAAR,CAA9B0G,CAAhB;EACA,IAAI,CAACK,OAAL,EAAc;IACZ,OAAO,IAAP;EACD;EACD,OAAO1G,KAAK,CAACC,OAAND,CAAcL,OAAdK,CAAAA,GAAyB0G,OAAzB1G,GAAmC0G,OAAO,CAAC,CAAD,CAAjD;AACD;AAEM,IAAME,gBAAgB,IAAA,iBAAA,GAAA,CAAA,CAAA,EAAA,CAAA,CAAA,EAAA,gBAAA,CAAA,SAAA,CAAA,EAAA,iBAAA,EAC1BC,gBAAAA,CAAAA,eAAAA,CAAgBzE,GADU,EACJmC,gBADI,CAAA,EAAA,CAAA,CAAA,EAAA,gBAAA,CAAA,SAAA,CAAA,EAAA,iBAAA,EAE1BsC,gBAAAA,CAAAA,eAAAA,CAAgB1C,OAFU,EAEAM,cAFA,CAAA,EAAA,CAAA,CAAA,EAAA,gBAAA,CAAA,SAAA,CAAA,EAAA,iBAAA,EAG1BoC,gBAAAA,CAAAA,eAAAA,CAAgBC,GAHU,EAGJpH,cAHI,CAAA,EAAA,CAAA,CAAA,EAAA,gBAAA,CAAA,SAAA,CAAA,EAAA,iBAAA,EAI1BmH,gBAAAA,CAAAA,eAAAA,CAAgBE,QAJU,EAICN,sBAJD,CAAA,EAAA,iBAAA,CAAtB;;AAOA,IAAMO,UAAU,GAAG;EACxBvC,cAAc,EAAdA,cADwB;EAExB/E,cAAc,EAAdA,cAFwB;EAGxB6E,gBAAgB,EAAhBA,gBAHwB;EAIxB6B,mBAAmB,EAAnBA,mBAJwB;EAKxBK,sBAAsB,EAAtBA,sBALwB;EAMxBnD,uBAAuB,EAAvBA,uBANwB;EAOxB7C,iBAAiB,EAAjBA,iBAPwB;EAQxBO,uBAAuB,EAAvBA,uBARwB;EASxBmE,SAAS,EAATA;AATwB,CAAnB","sourcesContent":["// Copyright (c) 2021 Uber Technologies, Inc.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a copy\n// of this software and associated documentation files (the \"Software\"), to deal\n// in the Software without restriction, including without limitation the rights\n// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n// copies of the Software, and to permit persons to whom the Software is\n// furnished to do so, subject to the following conditions:\n//\n// The above copyright notice and this permission notice shall be included in\n// all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n// THE SOFTWARE.\n\nimport {csvParseRows, csvFormatRows} from 'd3-dsv';\nimport {range} from 'd3-array';\nimport {console as globalConsole} from 'global/window';\nimport assert from 'assert';\nimport {Analyzer, DATA_TYPES as AnalyzerDATA_TYPES} from 'type-analyzer';\nimport normalize from '@mapbox/geojson-normalize';\nimport {ALL_FIELD_TYPES, DATASET_FORMATS} from 'constants/default-settings';\nimport {notNullorUndefined, parseFieldValue} from 'utils/data-utils';\nimport KeplerGlSchema from 'schemas';\nimport {GUIDES_FILE_FORMAT_DOC} from 'constants/user-guides';\nimport {isPlainObject, toArray} from 'utils/utils';\n\nexport const ACCEPTED_ANALYZER_TYPES = [\n  AnalyzerDATA_TYPES.DATE,\n  AnalyzerDATA_TYPES.TIME,\n  AnalyzerDATA_TYPES.DATETIME,\n  AnalyzerDATA_TYPES.NUMBER,\n  AnalyzerDATA_TYPES.INT,\n  AnalyzerDATA_TYPES.FLOAT,\n  AnalyzerDATA_TYPES.BOOLEAN,\n  AnalyzerDATA_TYPES.STRING,\n  AnalyzerDATA_TYPES.GEOMETRY,\n  AnalyzerDATA_TYPES.GEOMETRY_FROM_STRING,\n  AnalyzerDATA_TYPES.PAIR_GEOMETRY_FROM_STRING,\n  AnalyzerDATA_TYPES.ZIPCODE,\n  AnalyzerDATA_TYPES.ARRAY,\n  AnalyzerDATA_TYPES.OBJECT\n];\n\n// if any of these value occurs in csv, parse it to null;\n// const CSV_NULLS = ['', 'null', 'NULL', 'Null', 'NaN', '/N'];\n// matches empty string\nexport const CSV_NULLS = /^(null|NULL|Null|NaN|\\/N||)$/;\n\nconst IGNORE_DATA_TYPES = Object.keys(AnalyzerDATA_TYPES).filter(\n  type => !ACCEPTED_ANALYZER_TYPES.includes(type)\n);\n\nexport const PARSE_FIELD_VALUE_FROM_STRING = {\n  [ALL_FIELD_TYPES.boolean]: {\n    valid: d => typeof d === 'boolean',\n    parse: d => d === 'true' || d === 'True' || d === 'TRUE' || d === '1'\n  },\n  [ALL_FIELD_TYPES.integer]: {\n    valid: d => parseInt(d, 10) === d,\n    parse: d => parseInt(d, 10)\n  },\n  [ALL_FIELD_TYPES.timestamp]: {\n    valid: (d, field) =>\n      ['x', 'X'].includes(field.format) ? typeof d === 'number' : typeof d === 'string',\n    parse: (d, field) => (['x', 'X'].includes(field.format) ? Number(d) : d)\n  },\n  [ALL_FIELD_TYPES.real]: {\n    valid: d => parseFloat(d) === d,\n    // Note this will result in NaN for some string\n    parse: parseFloat\n  }\n};\n\n/**\n * Process csv data, output a data object with `{fields: [], rows: []}`.\n * The data object can be wrapped in a `dataset` and pass to [`addDataToMap`](../actions/actions.md#adddatatomap)\n * @param rawData raw csv string\n * @returns  data object `{fields: [], rows: []}` can be passed to addDataToMaps\n * @type {typeof import('./data-processor').processCsvData}\n * @public\n * @example\n * import {processCsvData} from 'kepler.gl/processors';\n *\n * const testData = `gps_data.utc_timestamp,gps_data.lat,gps_data.lng,gps_data.types,epoch,has_result,id,time,begintrip_ts_utc,begintrip_ts_local,date\n * 2016-09-17 00:09:55,29.9900937,31.2590542,driver_analytics,1472688000000,False,1,2016-09-23T00:00:00.000Z,2016-10-01 09:41:39+00:00,2016-10-01 09:41:39+00:00,2016-09-23\n * 2016-09-17 00:10:56,29.9927699,31.2461142,driver_analytics,1472688000000,False,2,2016-09-23T00:00:00.000Z,2016-10-01 09:46:37+00:00,2016-10-01 16:46:37+00:00,2016-09-23\n * 2016-09-17 00:11:56,29.9907261,31.2312742,driver_analytics,1472688000000,False,3,2016-09-23T00:00:00.000Z,,,2016-09-23\n * 2016-09-17 00:12:58,29.9870074,31.2175827,driver_analytics,1472688000000,False,4,2016-09-23T00:00:00.000Z,,,2016-09-23`\n *\n * const dataset = {\n *  info: {id: 'test_data', label: 'My Csv'},\n *  data: processCsvData(testData)\n * };\n *\n * dispatch(addDataToMap({\n *  datasets: [dataset],\n *  options: {centerMap: true, readOnly: true}\n * }));\n */\nexport function processCsvData(rawData, header) {\n  let rows;\n  let headerRow;\n\n  if (typeof rawData === 'string') {\n    const parsedRows = csvParseRows(rawData);\n\n    if (!Array.isArray(parsedRows) || parsedRows.length < 2) {\n      // looks like an empty file, throw error to be catch\n      throw new Error('process Csv Data Failed: CSV is empty');\n    }\n    headerRow = parsedRows[0];\n    rows = parsedRows.slice(1);\n  } else if (Array.isArray(rawData) && rawData.length) {\n    rows = rawData;\n    headerRow = header;\n\n    if (!Array.isArray(headerRow)) {\n      // if data is passed in as array of rows and missing header\n      // assume first row is header\n      headerRow = rawData[0];\n      rows = rawData.slice(1);\n    }\n  }\n\n  if (!rows || !headerRow) {\n    throw new Error('invalid input passed to processCsvData');\n  }\n\n  // here we assume the csv file that people uploaded will have first row\n  // as name of the column\n\n  cleanUpFalsyCsvValue(rows);\n  // No need to run type detection on every data point\n  // here we get a list of none null values to run analyze on\n  const sample = getSampleForTypeAnalyze({fields: headerRow, rows});\n  const fields = getFieldsFromData(sample, headerRow);\n  const parsedRows = parseRowsByFields(rows, fields);\n\n  return {fields, rows: parsedRows};\n}\n\n/**\n * Parse rows of csv by analyzed field types. So that `'1'` -> `1`, `'True'` -> `true`\n * @param {Array<Array>} rows\n * @param {Array<Object>} fields\n */\nexport function parseRowsByFields(rows, fields) {\n  // Edit rows in place\n  const geojsonFieldIdx = fields.findIndex(f => f.name === '_geojson');\n  fields.forEach(parseCsvRowsByFieldType.bind(null, rows, geojsonFieldIdx));\n\n  return rows;\n}\n/**\n * Getting sample data for analyzing field type.\n *\n * @type {typeof import('./data-processor').getSampleForTypeAnalyze}\n */\nexport function getSampleForTypeAnalyze({fields, rows, sampleCount = 50}) {\n  const total = Math.min(sampleCount, rows.length);\n  // const fieldOrder = fields.map(f => f.name);\n  const sample = range(0, total, 1).map(d => ({}));\n\n  // collect sample data for each field\n  fields.forEach((field, fieldIdx) => {\n    // data counter\n    let i = 0;\n    // sample counter\n    let j = 0;\n\n    while (j < total) {\n      if (i >= rows.length) {\n        // if depleted data pool\n        sample[j][field] = null;\n        j++;\n      } else if (notNullorUndefined(rows[i][fieldIdx])) {\n        const value = rows[i][fieldIdx];\n        sample[j][field] = typeof value === 'string' ? value.trim() : value;\n        j++;\n        i++;\n      } else {\n        i++;\n      }\n    }\n  });\n\n  return sample;\n}\n\n/**\n * Convert falsy value in csv including `'', 'null', 'NULL', 'Null', 'NaN'` to `null`,\n * so that type-analyzer won't detect it as string\n *\n * @param {Array<Array>} rows\n */\nfunction cleanUpFalsyCsvValue(rows) {\n  const re = new RegExp(CSV_NULLS, 'g');\n  for (let i = 0; i < rows.length; i++) {\n    for (let j = 0; j < rows[i].length; j++) {\n      // analyzer will set any fields to 'string' if there are empty values\n      // which will be parsed as '' by d3.csv\n      // here we parse empty data as null\n      // TODO: create warning when deltect `CSV_NULLS` in the data\n      if (typeof rows[i][j] === 'string' && rows[i][j].match(re)) {\n        rows[i][j] = null;\n      }\n    }\n  }\n}\n\n/**\n * Process uploaded csv file to parse value by field type\n *\n * @param rows\n * @param geoFieldIdx field index\n * @param field\n * @param i\n * @type {typeof import('./data-processor').parseCsvRowsByFieldType}\n */\nexport function parseCsvRowsByFieldType(rows, geoFieldIdx, field, i) {\n  const parser = PARSE_FIELD_VALUE_FROM_STRING[field.type];\n  if (parser) {\n    // check first not null value of it's already parsed\n    const first = rows.find(r => notNullorUndefined(r[i]));\n    if (!first || parser.valid(first[i], field)) {\n      return;\n    }\n    rows.forEach(row => {\n      // parse string value based on field type\n      if (row[i] !== null) {\n        row[i] = parser.parse(row[i], field);\n        if (geoFieldIdx > -1 && row[geoFieldIdx] && row[geoFieldIdx].properties) {\n          row[geoFieldIdx].properties[field.name] = row[i];\n        }\n      }\n    });\n  }\n}\n\n/**\n * Analyze field types from data in `string` format, e.g. uploaded csv.\n * Assign `type`, `fieldIdx` and `format` (timestamp only) to each field\n *\n * @param data array of row object\n * @param fieldOrder array of field names as string\n * @returns formatted fields\n * @type {typeof import('./data-processor').getFieldsFromData}\n * @public\n * @example\n *\n * import {getFieldsFromData} from 'kepler.gl/processors';\n * const data = [{\n *   time: '2016-09-17 00:09:55',\n *   value: '4',\n *   surge: '1.2',\n *   isTrip: 'true',\n *   zeroOnes: '0'\n * }, {\n *   time: '2016-09-17 00:30:08',\n *   value: '3',\n *   surge: null,\n *   isTrip: 'false',\n *   zeroOnes: '1'\n * }, {\n *   time: null,\n *   value: '2',\n *   surge: '1.3',\n *   isTrip: null,\n *   zeroOnes: '1'\n * }];\n *\n * const fieldOrder = ['time', 'value', 'surge', 'isTrip', 'zeroOnes'];\n * const fields = getFieldsFromData(data, fieldOrder);\n * // fields = [\n * // {name: 'time', format: 'YYYY-M-D H:m:s', fieldIdx: 1, type: 'timestamp'},\n * // {name: 'value', format: '', fieldIdx: 4, type: 'integer'},\n * // {name: 'surge', format: '', fieldIdx: 5, type: 'real'},\n * // {name: 'isTrip', format: '', fieldIdx: 6, type: 'boolean'},\n * // {name: 'zeroOnes', format: '', fieldIdx: 7, type: 'integer'}];\n *\n */\nexport function getFieldsFromData(data, fieldOrder) {\n  // add a check for epoch timestamp\n  const metadata = Analyzer.computeColMeta(\n    data,\n    [\n      {regex: /.*geojson|all_points/g, dataType: 'GEOMETRY'},\n      {regex: /.*census/g, dataType: 'STRING'}\n    ],\n    {ignoredDataTypes: IGNORE_DATA_TYPES}\n  );\n\n  const {fieldByIndex} = renameDuplicateFields(fieldOrder);\n\n  const result = fieldOrder.map((field, index) => {\n    const name = fieldByIndex[index];\n\n    const fieldMeta = metadata.find(m => m.key === field);\n    const {type, format} = fieldMeta || {};\n\n    return {\n      name,\n      id: name,\n      displayName: name,\n      format,\n      fieldIdx: index,\n      type: analyzerTypeToFieldType(type),\n      analyzerType: type,\n      valueAccessor: dc => d => {\n        return dc.valueAt(d.index, index);\n      }\n    };\n  });\n\n  // @ts-ignore\n  return result;\n}\n\n/**\n * pass in an array of field names, rename duplicated one\n * and return a map from old field index to new name\n *\n * @param {Array} fieldOrder\n * @returns {Object} new field name by index\n */\nexport function renameDuplicateFields(fieldOrder) {\n  return fieldOrder.reduce(\n    (accu, field, i) => {\n      const {allNames} = accu;\n      let fieldName = field;\n\n      // add a counter to duplicated names\n      if (allNames.includes(field)) {\n        let counter = 0;\n        while (allNames.includes(`${field}-${counter}`)) {\n          counter++;\n        }\n        fieldName = `${field}-${counter}`;\n      }\n\n      accu.fieldByIndex[i] = fieldName;\n      accu.allNames.push(fieldName);\n\n      return accu;\n    },\n    {allNames: [], fieldByIndex: {}}\n  );\n}\n\n/**\n * Convert type-analyzer output to kepler.gl field types\n *\n * @param aType\n * @returns corresponding type in `ALL_FIELD_TYPES`\n * @type {typeof import('./data-processor').analyzerTypeToFieldType}}\n */\n/* eslint-disable complexity */\nexport function analyzerTypeToFieldType(aType) {\n  const {\n    DATE,\n    TIME,\n    DATETIME,\n    NUMBER,\n    INT,\n    FLOAT,\n    BOOLEAN,\n    STRING,\n    GEOMETRY,\n    GEOMETRY_FROM_STRING,\n    PAIR_GEOMETRY_FROM_STRING,\n    ZIPCODE,\n    ARRAY,\n    OBJECT\n  } = AnalyzerDATA_TYPES;\n\n  // TODO: un recognized types\n  // CURRENCY PERCENT NONE\n  switch (aType) {\n    case DATE:\n      return ALL_FIELD_TYPES.date;\n    case TIME:\n    case DATETIME:\n      return ALL_FIELD_TYPES.timestamp;\n    case FLOAT:\n      return ALL_FIELD_TYPES.real;\n    case INT:\n      return ALL_FIELD_TYPES.integer;\n    case BOOLEAN:\n      return ALL_FIELD_TYPES.boolean;\n    case GEOMETRY:\n    case GEOMETRY_FROM_STRING:\n    case PAIR_GEOMETRY_FROM_STRING:\n    case ARRAY:\n    case OBJECT:\n      // TODO: create a new data type for objects and arrays\n      return ALL_FIELD_TYPES.geojson;\n    case NUMBER:\n    case STRING:\n    case ZIPCODE:\n      return ALL_FIELD_TYPES.string;\n    default:\n      globalConsole.warn(`Unsupported analyzer type: ${aType}`);\n      return ALL_FIELD_TYPES.string;\n  }\n}\n/* eslint-enable complexity */\n\n/**\n * Process data where each row is an object, output can be passed to [`addDataToMap`](../actions/actions.md#adddatatomap)\n * NOTE: This function may mutate input.\n * @param rawData an array of row object, each object should have the same number of keys\n * @returns dataset containing `fields` and `rows`\n * @type {typeof import('./data-processor').processRowObject}\n * @public\n * @example\n * import {addDataToMap} from 'kepler.gl/actions';\n * import {processRowObject} from 'kepler.gl/processors';\n *\n * const data = [\n *  {lat: 31.27, lng: 127.56, value: 3},\n *  {lat: 31.22, lng: 126.26, value: 1}\n * ];\n *\n * dispatch(addDataToMap({\n *  datasets: {\n *    info: {label: 'My Data', id: 'my_data'},\n *    data: processRowObject(data)\n *  }\n * }));\n */\nexport function processRowObject(rawData) {\n  if (!Array.isArray(rawData) || !rawData.length) {\n    return null;\n  }\n\n  const keys = Object.keys(rawData[0]);\n  const rows = rawData.map(d => keys.map(key => d[key]));\n\n  // row object an still contain values like `Null` or `N/A`\n  cleanUpFalsyCsvValue(rows);\n\n  return processCsvData(rows, keys);\n}\n\n/**\n * Process GeoJSON [`FeatureCollection`](http://wiki.geojson.org/GeoJSON_draft_version_6#FeatureCollection),\n * output a data object with `{fields: [], rows: []}`.\n * The data object can be wrapped in a `dataset` and passed to [`addDataToMap`](../actions/actions.md#adddatatomap)\n * NOTE: This function may mutate input.\n *\n * @param  rawData raw geojson feature collection\n * @returns  dataset containing `fields` and `rows`\n * @type {typeof import('./data-processor').processGeojson}\n * @public\n * @example\n * import {addDataToMap} from 'kepler.gl/actions';\n * import {processGeojson} from 'kepler.gl/processors';\n *\n * const geojson = {\n * \t\"type\" : \"FeatureCollection\",\n * \t\"features\" : [{\n * \t\t\"type\" : \"Feature\",\n * \t\t\"properties\" : {\n * \t\t\t\"capacity\" : \"10\",\n * \t\t\t\"type\" : \"U-Rack\"\n * \t\t},\n * \t\t\"geometry\" : {\n * \t\t\t\"type\" : \"Point\",\n * \t\t\t\"coordinates\" : [ -71.073283, 42.417500 ]\n * \t\t}\n * \t}]\n * };\n *\n * dispatch(addDataToMap({\n *  datasets: {\n *    info: {\n *      label: 'Sample Taxi Trips in New York City',\n *      id: 'test_trip_data'\n *    },\n *    data: processGeojson(geojson)\n *  }\n * }));\n */\nexport function processGeojson(rawData) {\n  const normalizedGeojson = normalize(rawData);\n\n  if (!normalizedGeojson || !Array.isArray(normalizedGeojson.features)) {\n    const error = new Error(\n      `Read File Failed: File is not a valid GeoJSON. Read more about [supported file format](${GUIDES_FILE_FORMAT_DOC})`\n    );\n    throw error;\n    // fail to normalize geojson\n  }\n\n  // getting all feature fields\n  const allDataRows = [];\n  for (let i = 0; i < normalizedGeojson.features.length; i++) {\n    const f = normalizedGeojson.features[i];\n    if (f.geometry) {\n      allDataRows.push({\n        // add feature to _geojson field\n        _geojson: f,\n        ...(f.properties || {})\n      });\n    }\n  }\n  // get all the field\n  const fields = allDataRows.reduce((prev, curr) => {\n    Object.keys(curr).forEach(key => {\n      if (!prev.includes(key)) {\n        prev.push(key);\n      }\n    });\n    return prev;\n  }, []);\n\n  // make sure each feature has exact same fields\n  allDataRows.forEach(d => {\n    fields.forEach(f => {\n      if (!(f in d)) {\n        d[f] = null;\n        d._geojson.properties[f] = null;\n      }\n    });\n  });\n\n  return processRowObject(allDataRows);\n}\n\n/**\n * On export data to csv\n * @param {import('utils/table-utils/data-container-interface').DataContainerInterface} dataContainer\n * @param {Array<Object>} fields `dataset.fields`\n * @returns {string} csv string\n */\nexport function formatCsv(dataContainer, fields) {\n  const columns = fields.map(f => f.displayName || f.name);\n  const formattedData = [columns];\n\n  // parse geojson object as string\n  for (const row of dataContainer.rows(true)) {\n    formattedData.push(row.map((d, i) => parseFieldValue(d, fields[i].type)));\n  }\n\n  return csvFormatRows(formattedData);\n}\n\n/**\n * Validate input data, adding missing field types, rename duplicate columns\n * @type {typeof import('./data-processor').validateInputData}\n */\nexport function validateInputData(data) {\n  if (!isPlainObject(data)) {\n    assert('addDataToMap Error: dataset.data cannot be null');\n    return null;\n  } else if (!Array.isArray(data.fields)) {\n    assert('addDataToMap Error: expect dataset.data.fields to be an array');\n    return null;\n  } else if (!Array.isArray(data.rows)) {\n    assert('addDataToMap Error: expect dataset.data.rows to be an array');\n    return null;\n  }\n\n  const {fields, rows} = data;\n\n  // check if all fields has name, format and type\n  const allValid = fields.every((f, i) => {\n    if (!isPlainObject(f)) {\n      assert(`fields needs to be an array of object, but find ${typeof f}`);\n      fields[i] = {};\n    }\n\n    if (!f.name) {\n      assert(`field.name is required but missing in ${JSON.stringify(f)}`);\n      // assign a name\n      fields[i].name = `column_${i}`;\n    }\n\n    if (!ALL_FIELD_TYPES[f.type]) {\n      assert(`unknown field type ${f.type}`);\n      return false;\n    }\n\n    if (!fields.every(field => field.analyzerType)) {\n      assert('field missing analyzerType');\n      return false;\n    }\n\n    // check time format is correct based on first 10 not empty element\n    if (f.type === ALL_FIELD_TYPES.timestamp) {\n      const sample = findNonEmptyRowsAtField(rows, i, 10).map(r => ({ts: r[i]}));\n      const analyzedType = Analyzer.computeColMeta(sample)[0];\n      return analyzedType && analyzedType.category === 'TIME' && analyzedType.format === f.format;\n    }\n\n    return true;\n  });\n\n  if (allValid) {\n    return {rows, fields};\n  }\n\n  // if any field has missing type, recalculate it for everyone\n  // because we simply lost faith in humanity\n  const sampleData = getSampleForTypeAnalyze({\n    fields: fields.map(f => f.name),\n    rows\n  });\n  const fieldOrder = fields.map(f => f.name);\n  const meta = getFieldsFromData(sampleData, fieldOrder);\n  const updatedFields = fields.map((f, i) => ({\n    ...f,\n    type: meta[i].type,\n    format: meta[i].format,\n    analyzerType: meta[i].analyzerType\n  }));\n\n  return {fields: updatedFields, rows};\n}\n\nfunction findNonEmptyRowsAtField(rows, fieldIdx, total) {\n  const sample = [];\n  let i = 0;\n  while (sample.length < total && i < rows.length) {\n    if (notNullorUndefined(rows[i][fieldIdx])) {\n      sample.push(rows[i]);\n    }\n    i++;\n  }\n  return sample;\n}\n\n/**\n * Process saved kepler.gl json to be pass to [`addDataToMap`](../actions/actions.md#adddatatomap).\n * The json object should contain `datasets` and `config`.\n * @param {Object} rawData\n * @param {Array} rawData.datasets\n * @param {Object} rawData.config\n * @returns {Object} datasets and config `{datasets: {}, config: {}}`\n * @public\n * @example\n * import {addDataToMap} from 'kepler.gl/actions';\n * import {processKeplerglJSON} from 'kepler.gl/processors';\n *\n * dispatch(addDataToMap(processKeplerglJSON(keplerGlJson)));\n */\nexport function processKeplerglJSON(rawData) {\n  return rawData ? KeplerGlSchema.load(rawData.datasets, rawData.config) : null;\n}\n\n/**\n * Parse a single or an array of datasets saved using kepler.gl schema\n * @param {Array | Array<Object>} rawData\n */\nexport function processKeplerglDataset(rawData) {\n  if (!rawData) {\n    return null;\n  }\n\n  const results = KeplerGlSchema.parseSavedData(toArray(rawData));\n  if (!results) {\n    return null;\n  }\n  return Array.isArray(rawData) ? results : results[0];\n}\n\nexport const DATASET_HANDLERS = {\n  [DATASET_FORMATS.row]: processRowObject,\n  [DATASET_FORMATS.geojson]: processGeojson,\n  [DATASET_FORMATS.csv]: processCsvData,\n  [DATASET_FORMATS.keplergl]: processKeplerglDataset\n};\n\nexport const Processors = {\n  processGeojson,\n  processCsvData,\n  processRowObject,\n  processKeplerglJSON,\n  processKeplerglDataset,\n  analyzerTypeToFieldType,\n  getFieldsFromData,\n  parseCsvRowsByFieldType,\n  formatCsv\n};\n"]},"metadata":{},"sourceType":"script"}